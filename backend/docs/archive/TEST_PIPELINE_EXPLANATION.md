# LexiSurvey Test Pipeline Explanation

## Overview

The test pipeline is a **3-stage verification system** that ensures the complete LexiSurvey integration works correctly from frontend â†’ backend â†’ database.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TEST PIPELINE                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Stage 1: CONFUSED_WITH Verificationâ”‚
        â”‚  (Neo4j Relationship Check)           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Stage 2: Integration Tests          â”‚
        â”‚  (Frontend â†’ Backend â†’ Database)     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Stage 3: CONFUSED_WITH Usage Tests  â”‚
        â”‚  (Relationship Usage Verification)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    âœ… All Tests Pass
```

## Pipeline Execution Flow

### Entry Point: `run_integration_tests.sh`

The pipeline starts with a bash script that orchestrates all tests:

```bash
./run_integration_tests.sh
```

**What it does:**
1. âœ… Validates environment (checks for `requirements.txt`)
2. âœ… Activates virtual environment (if exists)
3. âœ… Installs test dependencies (`pytest`, `httpx`)
4. âœ… Runs all 3 test stages sequentially
5. âœ… Stops on first failure (`set -e`)
6. âœ… Provides colored output (green âœ… / red âŒ)

---

## Stage 1: CONFUSED_WITH Verification

**Script**: `scripts/verify_confused_with.py`

**Purpose**: Verify that Neo4j has the required CONFUSED_WITH relationships for trap generation.

### What It Checks:

```
1. Connection Test
   â””â”€> Can we connect to Neo4j? âœ…

2. Relationship Count
   â””â”€> How many CONFUSED_WITH relationships exist?
       Expected: > 0
       
3. Relationship Properties
   â””â”€> Do relationships have required properties?
       - reason (Look-alike, Sound-alike, Semantic)
       - distance (Levenshtein distance)
       - source (adversary_builder_v7.1)
       
4. Sample Relationships
   â””â”€> Display 10 sample relationships for inspection
   
5. Top Words
   â””â”€> Which words have the most CONFUSED_WITH relationships?
   
6. Common Words Coverage
   â””â”€> Do common words (rank < 2000) have relationships?
```

### Example Output:
```
==========================================
CONFUSED_WITH Relationships Verification
==========================================
âœ… Connected to Neo4j

ðŸ“Š Total CONFUSED_WITH relationships: 1234

ðŸ“ˆ Relationships by reason:
   - Look-alike: 456
   - Sound-alike: 234
   - Semantic: 544

ðŸ“‹ Sample relationships:
   establish -[:CONFUSED_WITH {reason: 'Look-alike', distance: 2}]-> estimate
   ...

âœ… Verification complete!
```

### Why This Stage Matters:
- **Without CONFUSED_WITH relationships**, the survey can't generate trap options
- **Trap options** are crucial for question quality
- **Early detection** prevents integration test failures later

---

## Stage 2: Integration Tests

**File**: `tests/test_survey_integration.py`

**Purpose**: Test the complete flow from API request â†’ database persistence.

### Test Flow Diagram:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Integration Test Flow                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Test 1: test_start_survey_creates_session
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Frontend Request
    â”‚
    â–¼
POST /api/v1/survey/start
    â”‚
    â”œâ”€> Backend creates SurveyState
    â”œâ”€> Engine generates first question
    â””â”€> Database writes:
        â”œâ”€> survey_sessions (new session)
        â”œâ”€> survey_history (empty history)
        â””â”€> survey_questions (first question)
    â”‚
    â–¼
Verify:
âœ… Response has session_id
âœ… Session exists in PostgreSQL
âœ… History record created
âœ… Question stored correctly


Test 2: test_submit_answer_updates_session
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Frontend Request
    â”‚
    â–¼
POST /api/v1/survey/next?session_id=...
    â”‚
    â”œâ”€> Backend loads session from DB
    â”œâ”€> Engine grades answer
    â”œâ”€> Engine calculates next rank
    â””â”€> Database updates:
        â”œâ”€> survey_sessions (current_rank, status)
        â”œâ”€> survey_history (append new answer)
        â””â”€> survey_questions (store next question)
    â”‚
    â–¼
Verify:
âœ… Session state updated
âœ… History contains answer
âœ… Next question generated


Test 3: test_survey_completes_after_minimum_questions
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Frontend Requests (15+ times)
    â”‚
    â–¼
Loop: POST /api/v1/survey/next
    â”‚
    â”œâ”€> Each answer updates state
    â”œâ”€> After 15 questions: completion check
    â””â”€> Engine calculates metrics:
        â”œâ”€> Volume (Est. Reserves)
        â”œâ”€> Reach (Horizon)
        â””â”€> Density (Solidity)
    â”‚
    â–¼
Database writes:
    â”œâ”€> survey_results (final metrics)
    â””â”€> survey_sessions (status = 'completed')
    â”‚
    â–¼
Verify:
âœ… Survey completes after minimum questions
âœ… Metrics calculated correctly
âœ… Results saved to database
âœ… Session status = 'completed'


Test 4: test_session_persistence_across_requests
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Request 1: Start survey
    â”‚
    â””â”€> Creates session_id: "abc-123"
    â”‚
Request 2: Submit answer (uses session_id)
    â”‚
    â””â”€> Backend loads session from DB
    â””â”€> Updates history
    â”‚
Request 3: Submit another answer
    â”‚
    â””â”€> Backend loads session again
    â””â”€> History should contain BOTH answers
    â”‚
    â–¼
Verify:
âœ… Session persists across requests
âœ… History accumulates correctly
âœ… State is maintained
```

### Test Infrastructure:

**Fixtures** (provided by pytest):
```python
@pytest.fixture
def client():
    """FastAPI TestClient - simulates HTTP requests"""
    return TestClient(app)

@pytest.fixture
def db_conn():
    """PostgreSQL connection for database verification"""
    conn = PostgresConnection()
    yield conn  # Provide connection
    conn.close()  # Cleanup after test
```

**Test Execution**:
- Each test is **independent** (fresh database state)
- Tests use **real database connections** (not mocks)
- Tests verify **actual database records** (not just API responses)

---

## Stage 3: CONFUSED_WITH Usage Tests

**File**: `tests/test_confused_with_relationships.py`

**Purpose**: Verify that CONFUSED_WITH relationships are actually used in question generation.

### What It Tests:

```
Test 1: test_confused_with_relationships_exist
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Query Neo4j:
  MATCH ()-[r:CONFUSED_WITH]->()
  RETURN count(r)
  
Verify: count > 0


Test 2: test_confused_with_has_properties
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Query Neo4j:
  MATCH (source)-[r:CONFUSED_WITH]->(target)
  RETURN r.reason, r.distance, r.source
  
Verify:
âœ… All relationships have 'reason'
âœ… All relationships have 'distance'
âœ… All relationships have 'source'
âœ… Reason is one of: Look-alike, Sound-alike, Semantic


Test 3: test_confused_with_used_in_question_generation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Create test SurveyState
2. Call engine._generate_question_payload()
3. Check generated options:
   â””â”€> Are there trap options? (from CONFUSED_WITH)
   â””â”€> Do options have correct types?
   
Verify:
âœ… Question generated successfully
âœ… Trap options present (if relationships exist)
âœ… All option types present (target, trap, filler, unknown)


Test 4: test_confused_with_bidirectional
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Query Neo4j:
  MATCH (w:Word)-[:CONFUSED_WITH]->(other:Word)
  WHERE w.name = "establish"
  RETURN other.name
  
Verify:
âœ… Can query outgoing relationships
âœ… Relationships are accessible


Test 5: test_confused_with_for_common_words
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Query Neo4j:
  MATCH (w:Word)-[:CONFUSED_WITH]->(other:Word)
  WHERE w.frequency_rank < 2000
  RETURN count(DISTINCT w)
  
Verify:
âœ… Common words have relationships
âœ… High-frequency words are covered
```

### Why This Stage Matters:
- **Validates data quality**: Relationships exist AND are used
- **Catches integration issues**: Even if relationships exist, they might not be used correctly
- **Ensures question quality**: Trap options depend on these relationships

---

## Complete Pipeline Execution

### Example Run:

```bash
$ ./run_integration_tests.sh

==========================================
LexiSurvey Integration Tests
==========================================

Activating virtual environment...
Checking dependencies...

==========================================
1. Testing CONFUSED_WITH Relationships
==========================================
âœ… Connected to Neo4j
ðŸ“Š Total CONFUSED_WITH relationships: 1234
âœ… Verification complete!
âœ… CONFUSED_WITH verification passed

==========================================
2. Running Integration Tests
==========================================
test_start_survey_creates_session ... PASSED
test_submit_answer_updates_session ... PASSED
test_survey_completes_after_minimum_questions ... PASSED
test_session_persistence_across_requests ... PASSED
âœ… Integration tests passed

==========================================
3. Testing CONFUSED_WITH Usage
==========================================
test_confused_with_relationships_exist ... PASSED
test_confused_with_has_properties ... PASSED
test_confused_with_used_in_question_generation ... PASSED
test_confused_with_bidirectional ... PASSED
test_confused_with_for_common_words ... PASSED
âœ… CONFUSED_WITH tests passed

==========================================
âœ… All tests passed!
==========================================
```

---

## Failure Scenarios

### Stage 1 Fails:
```
âŒ CONFUSED_WITH verification failed
   â†’ No relationships found
   â†’ Solution: Run adversary_builder.py
```

### Stage 2 Fails:
```
âŒ Integration tests failed
   â†’ Database connection error
   â†’ Solution: Check DATABASE_URL
   
   â†’ Session not found
   â†’ Solution: Check database migrations
   
   â†’ API error
   â†’ Solution: Check backend logs
```

### Stage 3 Fails:
```
âŒ CONFUSED_WITH tests failed
   â†’ Relationships exist but not used
   â†’ Solution: Check engine._generate_options()
   
   â†’ Missing properties
   â†’ Solution: Re-run adversary_builder.py
```

---

## Key Design Decisions

### 1. **Sequential Execution**
- Tests run in order (Stage 1 â†’ 2 â†’ 3)
- Early failures stop the pipeline (`set -e`)
- **Why**: Stage 1 must pass for Stage 2 to work

### 2. **Real Database Connections**
- Tests use actual PostgreSQL and Neo4j connections
- No mocks or test databases
- **Why**: Verify real integration, not just code logic

### 3. **Independent Tests**
- Each test is self-contained
- Tests don't depend on each other
- **Why**: Easier debugging, can run tests individually

### 4. **Comprehensive Verification**
- Tests check API responses AND database state
- Tests verify both existence AND usage
- **Why**: Catch integration issues early

---

## Running Individual Stages

You can run stages independently:

```bash
# Stage 1 only
python scripts/verify_confused_with.py

# Stage 2 only
pytest tests/test_survey_integration.py -v

# Stage 3 only
pytest tests/test_confused_with_relationships.py -v

# Specific test
pytest tests/test_survey_integration.py::TestSurveyIntegration::test_start_survey_creates_session -v
```

---

## Integration with CI/CD

The pipeline can be integrated into CI/CD:

```yaml
# GitHub Actions example
- name: Run Integration Tests
  run: |
    cd backend
    ./run_integration_tests.sh
  env:
    DATABASE_URL: ${{ secrets.DATABASE_URL }}
    NEO4J_URI: ${{ secrets.NEO4J_URI }}
    NEO4J_USER: ${{ secrets.NEO4J_USER }}
    NEO4J_PASSWORD: ${{ secrets.NEO4J_PASSWORD }}
```

---

## Summary

The test pipeline is a **3-stage verification system** that:

1. âœ… **Verifies data exists** (CONFUSED_WITH relationships)
2. âœ… **Tests integration** (API â†’ Database flow)
3. âœ… **Validates usage** (Relationships used correctly)

This ensures the complete LexiSurvey system works end-to-end before deployment.


